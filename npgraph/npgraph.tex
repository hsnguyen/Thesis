\chapter{Integration of assembly graph into scaffolding pipeline}\label{ch:npgraph}
\thispagestyle{empty}
\vspace*{\fill}
\epigraph{\emph{Another quote}}
{Son Nguyen}

\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The idea of using assembly graph for scaffolding in \npscarf{} has been considered from the very beginning of the software design. However, the computational challenges hinder its real-time process ability thus neglected from the first versions of \npscarf{}. In the first section of this chapter, I will introduce the concept and model of the (SPAdes) assembly graph  which would be used as the input. The next section will describe the first attempt to apply this information into \npscarf{} for a better gap-filling. Finally, a real-time assembly graph bridging algorithm will be shown in a new tool, namely \npgraph{} together with its perfomances and properties in numerous use cases.

\section{Assembly graph}
%assembly graph
\npscarf{} is a hybrid assembler that essentially conducts scaffolding on the NGS contigs and then filling the gaps, without using information from the short-read assembly process about the formation of the contigs themselves. This is illustrated in Figure \ref{Fig:assembly} where the algorithm enhances step 2 and 3 by using nanopore long reads in an attempt to give more complete genome assemblies. 
However, NGS assemblers usually provide a richer source of information than just the contig sequences themselves, namely \emph{assembly graph}. 
For the graph-based approaches, either OLC or DBG, assembly graph stores the ultimate string content of DNA sequences and their links in its components: edges and vertices. 
This is usually resulted from running a simplification algorithm on the original graph built from input data, \EG{} tips clipping, bubble removing, error removal, and/or scaffolding using paired-end or mate-pair links \cite{Zerbino2008,BankevichNA2012}.

\begin{figure}[ht!]
\centering
\includegraphics[width=.7\textwidth]{images/bgraph.png}
\caption[An example of bidirected graph model]
{An example of bidirected graph model. Each node contains a DNA sequence that can be spelled as template(+) or reverse complement(-). There are four possible types of a bidirected edge as shown as ones from node $z$. Each edge has two possible spelling depends on the starting node, resulting in two sequences of template and reversed complement. According to the rule of bidirected graph traversal, we have the following valid paths spelled as: $(u+,z+,v+)$, $(u+,z+,t-)$, $(w-,z+,v+)$, $(w-,z+,t-)$ and in the opposite direction respectively $(v-,z-,u-)$, $(t+,z-,u-)$, $(v-,z-,w+)$, $(t+,z-,w+)$.}
\label{f:bgraph}
\end{figure}

%bidirected graph
Assembly graph is normally implemented by a directed graph data structure. 
In which, each component (vertex or edge, depends on particular implementation) storing a string has a corresponding counterpart for that string in reversed complement order \cite{Zerbino2008}.
To have a more compact representation of the graph, we employ the bidirected graph data structure instead.

%Formal definition of bidirected graph (convention on the GUI)
For a bidirected graph $G=\{V,E\}$, each edge has two directions associated with two nodes forming it. The direction here refers to a boolean value that represent either incoming or outgoing state.
Unlike an edge in a directed graph, a bidirected edge can be traversed in both ways, similar to the property of an undirected edge except the content of each traversed vertex is not unique, but direction-wised. This means that if there is a path from node A to B, or B is reachable from A, then the existence of the reversed path holds true, which means A is reachable from B as well. Thus another translation for the bidirected graph is an undirected graph of the directed vertices, which can be related directly the purpose of modeling connections of DNA sequences as nodes in a graph structure, regarding they are double-stranded (sense and antisense). The edge-based modeling, on the other hand, is more intuitive to work with; however in term of comprehensive understandings and implementations, the directed-node ideology is additionally helpful also.

\paragraph{Edge-based modeling} From this point of view, any edge $e \in E$ connecting an ordered pair of node $(u,v) \in V^2$ would fall into one out of four categories: $\blacktriangleright\blacktriangleright$, $\blacktriangleright\blacktriangleleft$, $\blacktriangleleft\blacktriangleright$ or $\blacktriangleleft\blacktriangleleft$. By modeling edge directions as such, the graph traversal is able to cover the double-stranded property of the DNA sequences (template/reverse complement) in vertices through edge-walkings. 
The rule is that if we follow the arrow, its associated vertex is spelled as it is (+) and if we traverse against the arrow direction, the corresponding vertex is spelled as reverse complement sequence (-). As mentioned before, there are 2 ways of traversing through an edge, \EG from u to v and from v to u, as illustrated in Figure~\ref{f:bgraph}.
\paragraph{Vertex-based modeling} From this angle, it is convenient to firstly introduce the definition of directed node,  $\overrightarrow{v}=(v,d_v) \in \overrightarrow{V}$, as a tuple of vertex $v$ and its associated direction $d_v \in D=\{in,out\}$.
In this case, a bidirected edge is almost similar to an undirected edge connecting two (directed) vertices, \EG an unique edge that connect $\overrightarrow{u}$ and $\overrightarrow{v}$ can be equally written as $(\overrightarrow{u}, \overrightarrow{v})$ or $(\overrightarrow{v}, \overrightarrow{u})$. These two forward and reverse edges would refers to the same bidirected edge, except the content will be different depending on the order of spelled directed nodes.

The two definitions are equivalent and their applications are interchangeable and combinative in our implementation. In summary, the meaning and spelling for a bidirected graph components is as follow:
\begin{itemize}
\item $u\blacktriangleright\blacktriangleright v$ equivalent to $(u-out, v-in)$: spelling $u+v+$ or $v-u-$
\item $u\blacktriangleright\blacktriangleleft v$ equivalent to $(u-out, v-out)$: spelling $u+v+$ or $v-u-$
\item $u\blacktriangleleft\blacktriangleright v$ equivalent to $(u-in, v-in)$: spelling $u-v+$ or $v-u+$
\item $u\blacktriangleleft\blacktriangleleft v$ equivalent to $(u-in, v-out)$: spelling $u-v-$ or $v+u+$
\end{itemize}

To create a valid path when traversing, two adjacent edges must obey the direction rule that similar to that of directed graph, that is a path which has an edge entering an intermediate node (not 2 ending nodes) must leaving that node on the next edge and vice versa, due to the allowance of traversing against the arrows in bidirected graph. More details will be discussed in the next section.

\section{Application of the assembly graph in \npscarf{}}
The first attempt of utilizing assembly graph is to integrating the information to the scaffolding algorithm for the gap-filling step thus increase the accuracy of the final assembly. This is due to the fact that the edges from assembly graph come from Illumina data with much higher accuracy (99.9\%) compared to nanopore data ($\approx$90\%), which usually require high abundance to generate a consensus read with comparative quality. 

As shown in Figure~\ref{f:gapfilling}, for the first approach of gap filling, which is implemented in the very first version of \npscarf{}, segments from nanopore reads corresponding to a gap are first extracted based on the alignments to the flanking regions. A set of these pileup segments are then undergone a consensus calling step by multiple sequence aligner \EG{} \emph{kalign} \cite{LassmannFS2009} or \emph{poaV2} \cite{Lee2002multiple,Lee2003generating,Grasso2004combining}, and the result sequence can later be used to fill in the gap. 

\begin{figure}[!ht]
\centering
\includegraphics[width=.7\linewidth]{images/gapfilling.jpg}
\caption[Two approached for gap filling in \npscarf{}]
{Two approached for gap filling in \npscarf{} : 1. using consensus sequences from long reads and 2. using corresponding path in the assembly graph.}
\label{f:gapfilling}
\end{figure}

\npscarf{} later versions utilize assembly graph information for the gap filling step. In which, assembly graph from SPAdes is also learned together with contigs used as pre-assemblies in the workflow shown in Figure~\ref{f:workflow}. It is worth mentioning that each of these contigs is made of a path by traversing the assembly graph and normally short-read assemblers allow backtracking this piece of information, \EG{} via "\emph{contigs.paths}" file output from \spades{}. 

Mathematically, of this thesis' scope, a (bidirected) path $p\in P$ in (bidirected) graph $G\{V,E\}$ is defined as a walk through a series of alternative vertices and edges that are connected together, given that the bidirected transition rule is hold true for every intermediate vertices. For example, from the edge-based modelling point of view, a path $p$ of size $k$ can be written as $p=\{v_0,e_1,v_1,e_2,v_2,\dots,v_{k-1},e_{k},v_k\}$ where $e_i$ is the bidirected edge connects $v_{i-1}$ and $v_{i+1}$ with every $1 \leq i < k$ and will determine the their directions in the walk. A path of size 0 contains only one vertex and no edge.
Importantly, the transition rule requires $dir(e_{i}, v_{i}) \neq dir(e_{i+1}, v_{i})$, $\forall 1 \leq i < k$ where $dir:(E,V)\rightarrow D$ is the function that returns direction (from vertex-based modelling) of a vertex on a given edge.

Using this decomposition, the corresponding components of the assembly graph (consecutive nodes) that make up the corresponding flanking tips of the gap are identified. Then by applying a searching algorithm, \EG{} Depth-First Search (DFS), on the graph, a set of candidate paths connecting two tipping nodes are determined. By selecting the path that maximize the likelihood given the long reads, the gap can be filled up by the sequence spelled out from it as shown in Algorithm \ref{algo:fillgap}. 

\begin{algorithm}[H]
\DontPrintSemicolon
\KwData{Assembly graph $G\{V,E\}$}
\KwIn{Bridge $B=(contig_1, contig_2)$ with gap}
\KwOut{Sequence to fill in the gap of $B$}
\Begin{
$p_1:=decompose(G,contig_1)$ \tcp*{decompose first contig into graph components}
$p_2:=decompose(G,contig_2)$ \tcp*{decompose second contig into graph components}
$\overrightarrow{v_1}:=p_1$.peek() \tcp*{get the last directed vertex of $p_1$}
$\overrightarrow{v_2}:=p_2$.getRoot() \tcp*{get the first directed vertex of $p_2$}
$p:=DFS(G,\overrightarrow{v_1},\overrightarrow{v_2})$ \tcp*{find a path connect these 2 tips}
\Return{$p$.spell()}
}
\caption{Pseudo-code for filling gap with assembly graph in \npscarf{}.}
\label{algo:fillgap}
\end{algorithm}

Theoretically, this approach can increase the accuracy of gap-filling step, however, offers limited capacity in reducing the mis-assemblies. The reason is that the ending components of a contig can be repetitive, make it impossible to confirm a genuine bridge with the existence of a path connect two tips as above. 
To deal with this issue, the assembly graph should be applied to \npscarf{} by completely using its components as the building blocks for the scaffolding algorithm instead of the original unlinked contigs. This idea lead to the development of \npgraph{} - a graph-based tool that can finish genomes in real-time.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%% npGraph %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Resolve assembly graph in real-time by long reads with \npgraph{}}
\subsection{Introduction}
Streaming assembly methods have been proved to be useful in saving time and resources compared to the traditional batch algorithms with examples included \EG $\mathtt{Faucet}$~\cite{Rozov2017faucet} and \npscarf{}~\cite{Cao2017scaffolding}. The first method allows the assembly graph to be constructed incrementally as long as reads are retrieved and processed. This practice is helpful dealing with huge short-read data set because it can significantly reduce the local storage for the reads, as well as save time for a DBG construction while waiting for the data being retrieved.

\npscarf{}, on the other hand, works on the available short-read assembly to scaffold the contigs using nanopore sequencing which is well-known by the real-time property. The completion of genome assembly along with the sequencing run provides explicit benefits in term of resource control and turn-around time for analysis~\cite{Cao2017scaffolding}.  
However, due to the greedy approach of a streaming algorithm, as well as being an alignment-based-only scaffolding mechanism, running the tool with default settings is suffered from mis-assemblies~\cite{Wick2017unicycler,Giordano2017}. In many case, the gap filling step has to rely on the low quality nanopore reads thus the accuracy of the final assembly is affected as well. 
To tackle the quality issue while maintaining its streaming execution, an assembly graph processing system is investigated as it would provide additional high-quality source of linking information for the assembly operations. 

After the construction of an assembly graph, the next step is to traverse the graph, resolve the repeats and identify the longest possible un-branched paths that would represents contigs for the final assembly.
Hybrid assembler using nanopore data to resolve the graph has been implemented in $\mathtt{hybridSPAdes}$ \cite{AntipovKM2015} or \unicycler{} \cite{Wick2017unicycler}. 
In general, the available tools employ batch-mode algorithms on the whole long-read data set to generate the final genome assembly. 
In which, the \spades{} hybrid assembly module, from its first step, exhaustively looks for the most likely paths (with mininum edit distance) on the graph for each of the long read given but only ones supported by at least two reads are attained. In the next step, these paths will be subjected to a decision-rule algorithm, namely $\mathtt{exSPAnder}$~\cite{Prjibelski2014}, for repeat resolution by step-by-step expansion, before output the final assembly.
On the other hand, \unicycler{}'s hybrid assembler will initially generate a consensus long read for each of the bridge from the batch data. 
The higher quality consensus reads are used to align with the assembly graph to find the best paths bridging pairs of anchored contigs.
While the later approach employs the completeness of the data  set from the very beginning for a consensus step, the former only iterates over the batch of possible paths and relies on a scoring system for the final decision of graph traversal. For that reason, the first direction is more suitable for a real-time pipeline.
    
However, the challenges to adapt this approach into a real-time mechanism are obvious and mainly come from the heavy path-finding task and the complication of self-improvement step which is critical to a streaming algorithm. 
A modified DFS algorithm and a voting system with accumulating scores calculation has been implemented to overcome these issues.
This results in \npgraph{}, an user-friendly tool with GUI that can traverse the assembly graph and scaffold its components in real-time as long as the nanopore sequencing process is running and continuously generating long reads.  


\subsection{Methods}
\subsubsection{Overview}
The input consists of Illumina assembly graph resulted from running assembler, e.g. \spades{}~\cite{BankevichNA2012}, $\mathtt{Velvet}$ \cite{Zerbino2008}, $\mathtt{AbySS}$ \cite{Simpson2009} on Illumina short reads, together with long reads from third generation sequencing technology (Oxford Nanopore Technology, Pacbio).
The long reads will be aligned with the contigs in the assembly graph to indicate longer paths that should be traversed. These local paths, given sufficient data, are expected to untangle the complicated graph and guide to the global Eulerian paths (or cycles if possible) that represent the entire genomic sequences. 

Basically the work flow of \npgraph{} can be divided into 3 main phases: abundance binning, graph resolving and assembly output. 
The first step will try to bin the contigs into different groups of \emph{population} based on their coverage. 
Each population would include contigs of the similar abundance in the final assembly sequences, \EG{} chromosome , plasmids, or even particular species genome in a metagenomics community.
The binning phase would assist to differentiate between repetitive contigs and unique ones. By using this information, in combination with path inducing from long reads, the assembly graph is then traversed and resolved in real-time. Finally, the graph is subjected to the last attempt of resolving and cleaning, as well as output the final results. The whole process can be managed by using either command-line interface or GUI.
\subsubsection{Pre-processing: identify repeat and unique contigs}
The purpose of this step is to investigate the sequencing properties of contigs, \IE{} length and \emph{k-mer} count, in combination with the graph topology, for an initial binning algorithm to determine multiplicity for each of them.
%\paragraph{Correct coverage bias due to GC content}
%The read coverage from Illumina data could be rectified by applying GC-content correction model \cite{BenjaminiS2012}.
%To be implemented.

\paragraph{Initial binning contigs into groups of abundances}
Each contig is represented as a node in the assembly graph and the edge between two nodes indicate their overlap (link) properties.
This step is to cluster the significant nodes (longer than 10kbp) into different sets, namely significant abundance groups, based on their coverage values. 

DBSCAN clustering algorithm \cite{Ester96adensity-based} is applied for the task.
The idea is to consider a coverage value of a significant node (which consists of more than 10,000 \emph{k-mers}) to be a sampled mean of a Poisson distribution (of \emph{k-mers} count). 
The metric is a distance function based on Kullback-Leibner divergence \cite{Kullback1951information}, or relative entropy, of two Poisson distributions.

Assume there are 2 Poisson distribution $P_1$ and $P_2$ with density functions $$p_1(x,\lambda_1)=\frac{e^{-\lambda_1}\lambda_1^x}{\Gamma(x+1)}$$ and $$p_2(x,\lambda_2)=\frac{e^{-\lambda_2}\lambda_2^x}{\Gamma(x+1)}$$ 
The Kullback-Leibner divergence from $P_2$ to $P_1$ is defined as:
$$D_{KL}(P_1||P_2)=\int_{-\infty}^{\infty} p_1(x)\log{\frac{p_1(x)}{p_2(x)}} dx$$
or in words,  it is the expectation of the logarithmic difference between the probabilities $P_1$ and $P_2$, where the expectation is taken with regard to $P_1$.

The log ratio of the density functions is
$$\log{\frac{p_1(x)}{p_2(x)}}=x\log{\frac{\lambda_1}{\lambda_2}}+\lambda_2-\lambda_1$$
take expectation of this expression with regard to $P_1$ with mean $\lambda_1$ we have
$$D_{KL}(P_1||P_2)=\lambda_1\log{\frac{\lambda_1}{\lambda_2}}+\lambda_2-\lambda_1$$

The metric we used is the distance defined as
$$D(P_1,P_2)=\frac{D_{KL}(P_1||P_2)+D_{KL}(P_2||P_1)}{2}=\frac{1}{2}(\lambda_1-\lambda_2)(\log{\lambda_1}-\log{\lambda_2})$$

\paragraph{Coverage re-estimation}
Due to the possible divergence of sequencing coverage relatively to the real abundance of sequences, especially the short ones, an optimization step is implemented to alleviate this issue. The coverage measure of nodes are spread throughout the graph via edges that connect them for comparison and calibration. 
The assignment of coverage to edges is also helpful to identify multiplicity in later step. 

The re-estimation is basically carried out by following two steps.
\begin{itemize}
\item[1.] From nodes coverage, estimate edges' value by quadratic unconstrained optimization of the least-square function:
$$\frac{1}{2}\sum_{i}{l_i((\sum{e^{+}_{i}}-c_i)^2+(\sum{e^{-}_{i}}-c_i)^2}$$
where $l_i$ and $c_i$ is the length and coverage of a node $i$ in the graph;

$\sum{e^{+}_{i}}$ and $\sum{e^{-}_{i}}$ indicates sum of the values of incoming and outgoing edges from $i$ respectively. 
Above function and be rewritten as:
$$f(x)=\frac{1}{2}x^TQx + b^Tx + r$$
and then being minimized by using Newton or gradient method.
\item[2.] Update nodes' coverage based on itself and its neighbor edges' measures.
\end{itemize}
The calibration is iterative until no further improvements are made or a threshold loop count is reached.
\paragraph{Multiplicity estimation}
Based on the coverage values of all the edges and the binning results from significant nodes, we induce the their occupations (number of times each edge is traversed, from which abundance group) in the final paths.
On the other hand , estimated multiplicities of insignificant nodes (of sequences with length less than $1,000$ bp) are only used as reference to calculate candidate paths' score in the next step due to greater variances in these figures.

\subsubsection{Untangling assembly graph by stream of nanopore data.}
\paragraph{Building bridges in real-time}
Bridge is the data structure designed for tracking the possible connections between two unique contigs (anchor nodes in the assembly graph). This approach was implemented in \npscarf{} gap-filling phase with assembly graph as in Figure \ref{f:gapfilling}.
% how bridge is connected, transformed multiplicity (real-time)
Here we take advantage of the graph topology and nodes' multiplicity information to employ a dynamic bridging mechanism.
This procedure considers the dynamic changing of multiplicity property for each node, meaning that a $n$-times repetitive node can become a unique node at certain time point when its $(n-1)$ occurrences are identified and assigned in appropriate unique paths. 

Other than \npscarf{}, a bridge in \npgraph{} has several completion levels. A bridge is only created with at least one unique contig as an end, if so it has level 1 of completion. If both ends are identified, the level is 2. The number is greater than that only if paths connecting two end are found. A bridge is known as fully complete (level 4) if there is only one unique linking path left. Given a bridge with 2 ends, a path finding algorithm (described in next section) is invoked to find all candidate paths. Each of these paths is given a score of alignment-based likelihood which are updated immediately as long as there is an appropriate long read being generated by the sequencer. As more nanopore data coming in, the divergence between candidates' score becomes greater and only the best ones are voted for the next round.

Whenever a bridge becomes complete thanks to the voting system, the assembly graph is \emph{transformed} or \emph{reduced} by replacing its unique path by an composite edge and removing any unique edges (edges coming from unique nodes) along the path. The assembly graph would have at least one edge less than the original after the reduction. The nodes located on the reduced path, other than 2 ends, also have their multiplicities subtracted by one and the bridge is marked as finally resolved without any further changing. 
\paragraph{Path finding algorithm}

\begin{algorithm}[!hpt]
\DontPrintSemicolon
\KwData{Assembly graph $G\{V,E\}$}
\KwIn{Bridge $B=(\overrightarrow{v_1}, \overrightarrow{v_2})$ with two ending unique bidirected nodes $\overrightarrow{v_1}, \overrightarrow{v_2}$}
\KwOut{Set of candidate paths $P$ connecting $B$}
\Begin{
$d$:=$B.length()$ \tcp*{length of the bridge or the distance between 2 ending nodes}
$M$:=$\mathtt{shortestTree}(\overrightarrow{v_2},d)$ \tcp*{build shortest tree from $\overrightarrow{v_2}$ with range $d$}
\If{$M.contain(\overrightarrow{v_1})$}{
    $S$:=new $Stack()$ \tcp*{stack of sets of edges to traverse}
    $edgesSet$:=$getEdges(\overrightarrow{v_1})$ \tcp*{get all bidirected edges going from $\overrightarrow{v_1}$}
    $S.push(edgesSet)$\;
    $p$:=new $Path(\overrightarrow{v_1})$ \tcp*{init a path that has $\overrightarrow{v_1}$ as root}
    \While{true}{
        $edgesSet$:=$S.peek()$\;
        \If{$edgesSet.isEmpty()$}{
            \If{$p.size() \leq 1$}{
                $\mathbf{break}$ \tcp*{stop the loop when there is no more edge to discover}
            }
        $S.pop()$\;
        $d$+=$p.peekNode.length()+p.popEdge().length()$\; 
        }
        \Else{
            $curEdge \coloneqq edgesSet.remove()$\;
            $\overrightarrow{v}$:=$curEdge.getOpposite(p.peekNode())$\;
            $S.push(getEdges(\overrightarrow{v}).includedIn(M))$\;
            $p.add(curEdge)$\;
            \If{reach $\overrightarrow{v_2}$ with reasonable $d$}{
                $P.add(p)$\;
            }
            $d$-=$\overrightarrow{v}.length()+curEdge.length()$\;
        }
    }
}


\Return{$P$}
}
\caption{Pseudo-code for finding paths connecting a bridge with 2 ends.}
\label{algo:findpath}
\end{algorithm}
% formal mathematical definition & DFS algorithm goes here...
In \npscarf{} with assembly graph, the path finding algorithm is the original DFS which becomes computational expensive when the traversing depth increases. For \npgraph{}, we implement a modified stack-based version utilizing Dijkstra's shortest path finding algorithm~\cite{Dijkstra1959} to reduce the search space.

Algorithm~\ref{algo:findpath} demonstrates the path finding module in general.
In which, function 

$\mathtt{shortestTree}(\overrightarrow{vertex},distance) : (V,Z) \rightarrow V^n$ (line 3)

builds a shortest tree rooted from $\overrightarrow{v}$, following its direction until a distance of approximately $d$ (with a tolerance regarding nanopore read error rate) is reached. This task is implemented based on Dijkstra algorithm.
This tree is used on line 4 and in function $includedIn()$ on line 19 to filter out any node or edge with ending nodes that do not belong to the tree.

Basically, the algorithm keeps track of a stack that contains sets of candidate edges to discover as for DFS traversal manner. During the traversal, a variable $d$ is updated as an estimation for the distance to the target. A hit is reported if the target node is reached with a reasonable distance \IE{} close to zero, within a given tolerance (line 21). 
A threshold for the traversing depth is set (150) to ignore too complicated and time-consuming path searching.

It is worth to mention that the $length()$ functions for node and edge are totally different. While the former returns the length of the sequence represented by the node, the latter is usually negative because an edge models a link between two nodes, which is normally an overlap (except for composite edges). For example, in a \emph{k-mers} DBG-deprived assembly graph, the value is $-k$. 
\subsubsection{Result extraction and output}
\npgraph{} reports assembly result in real-time by decomposing the assembly graph into a set of longest straight paths (LSP), each of the LSP will present a contig for the result.
A path $p=\{v_0,e_1,v_1,\ldots,v_{k-1},e_k,v_k\}$ of size $k$ is considered as straight if every edge along the path, $e_i, \forall i=1,\ldots,k$, must be the only option to traverse from either $v_{i-1}$ or $v_i$ following the transition rule.
To decompose the graph, we can just simply mask out all incoming/outgoing edges rooted from any node with in/out degree greater than 1 as demonstrated in Figure~\ref{figure:npgraph_decompose}. These edges are defined as branching edges and straight paths are stopped encountering them.

\begin{figure}[!hpt]
\centering
\includegraphics[width=.6\textwidth]{images/decompose.pdf}
\caption[Example of graph decomposition into longest straight paths]{Example of graph decomposition into longest straight paths. Branching edges are masked out (shaded) leaving only straight paths (bold colored) to report. There would be 3 contigs extracted by traversing along the straight paths here.}
\label{figure:npgraph_decompose}
\end{figure}
The decomposed graph is only used to report the contigs that can be extracted from an assembly graph at certain time point. For that reason, the branching edges are only masked but not removed from the original graph as they would be used for further bridging.

The final assembly output contains files in both FASTA and GFA v1 format (\url{https://github.com/GFA-spec/GFA-spec}). While the former only retains the actual genome sequences from the final decomposed graph, the latter output file can store almost every properties of the ultimate un-masked graph such as nodes, links and potential paths between them.
\subsubsection{User interface}
\begin{figure}[!hpt]
\centering
\parbox{\textwidth}{
    \parbox{.57\textwidth}{
        \subfloat{\includegraphics[width=\hsize]{images/dashboard.png}}
    }
    \hskip1em
    \parbox{.44\textwidth}{%
        \subfloat{\includegraphics[width=\hsize]{images/graph-view.png}}
        \vskip1em
        \subfloat{\includegraphics[width=\hsize]{images/console-view.png}}  
    }
}
\caption[\npgraph{} user interface]{\npgraph{} user interface including Console (\textbf{0}) and GUI components (\textbf{1}-\textbf{6}). The GUI consists of the Dashboard (\textbf{1}-\textbf{5}) and the Graph View (\textbf{6}). From the Dashboard there are 5 components as follow: \textbf{1} the assembly graph input field; \textbf{2} the long reads input field; \textbf{3} the aligner settings field; \textbf{4} control buttons (start/stop) to monitor the real-time scaffolding process; \textbf{5} the statistics plots for the assembly result.}
\label{figure:npgraph_gui}
\end{figure}

\npgraph{} can be invoked and fully function from the command-line interface. In addition, in order to aid the visualization of the assembly process, a GUI is developed as well.

The GUI includes the dashboard for control the settings of the program and another pop-up window for a simple visualization of the assembly graph in real-time (Figure~\ref{figure:npgraph_gui}).
In this interface, the assembly graph loading stage is separated from the actual assembly process so that users can check for a legal (and decent) graph first before carry out any further tasks. The box numbered \textbf{1} on Figure~\ref{figure:npgraph_gui} is designed for this task.
Only after an assembly graph is loaded successfully, users can move to box \textbf{2} to specify the nanopore input data.
Settings for an aligner (\bwa{} or \minimap{}) in box \textbf{3} is required if the input is the raw sequences in FASTA/FASTQ format. Another option is to run the alignment independently and provide SAM/BAM input for the next stage of bridging and assembly. This stage is controlled by buttons in box \textbf{4}: the START button ignites the process while the STOP button can prematurely terminate it and output the assembly result till that moment. The plots from the right panel (\textbf{5}) depicts real-time statistics of the assembly contigs inferred from the graph.
From the second window (\textbf{6}), the colored vertices imply unique contigs while the white ones involve either unspecified or repetitive elements. The number of colors (other than white) indicates cardinal of population set (\EG{} chromosome, plasmids, or different bins in metagenomics).

A proper combination of command line and GUI can provide an useful streaming pipeline that copes well with MinION output data. The practice is similar to the previous developed pipelines~\cite{CaoGC2016,Cao2017scaffolding,Nguyen2017barcode} that allow the analysis to take place abreast to a nanopore sequencing run.
\subsection{Results}
\subsubsection{Hybrid assembly for synthetic data sets}
For a preliminary testing, \npgraph{} is benchmarked against \npscarf{} and Unicycler \cite{Wick2017unicycler} version 0.4.6 on the latter's testing data. This data set is synthetic Illumina and nanopore raw data, generated \emph{in silico} based on random and available microbial references. There are three quality settings for each of the simulated raw data: good, medium, bad. In this comparison, we only considered the best quality ones.


\subsubsection{Hybrid assembly for real data sets}

\subsection{Conclusions}